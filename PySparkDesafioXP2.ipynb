{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "985cc9cc",
   "metadata": {},
   "source": [
    "# Projeto: Avaliando Modelo de Decision Tree para Previsão de Derrames\n",
    "\n",
    "                    \n",
    "* Dataset: stroke_data.csv obtido no [Kaggle](https://www.kaggle.com/fedesoriano/stroke-prediction-dataset).\n",
    "\n",
    "> Neste projeto, realizaremos uma breve análise exploratória dos dados, culminando na construção e avaliação de um modelo de Árvore de Decisão utilizando PySpark. O objetivo é prever casos de derrame (stroke) com base nos dados disponíveis.\n",
    "\n",
    "> Este projeto faz parte do módulo de Apache Spark da Pós-Graduação em Ciência de Dados da XP Educação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "234e717a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos criar o objeto sparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Spark entry point\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(\"Decision Tree\") \\\n",
    ".getOrCreate()\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19e14dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos ler o arquivo com os dados de eventos de derrame\n",
    "df = spark.read.csv('D:/Abf/7 - Pos_XP_Educacao/Cientista de Dados/Módulo 2/Desafio/stroke_data.csv',header=True, inferSchema='True')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ed8718e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----+------------+-------------+------------+-------------+--------------+-----------------+-----+---------------+------+\n",
      "|  0|gender| age|hypertension|heart_disease|ever_married|    work_type|Residence_type|avg_glucose_level|  bmi| smoking_status|stroke|\n",
      "+---+------+----+------------+-------------+------------+-------------+--------------+-----------------+-----+---------------+------+\n",
      "|  1|Female|18.0|           0|            0|          No|      Private|         Urban|            94.19|12.12|         smokes|     1|\n",
      "|  2|  Male|58.0|           1|            0|         Yes|      Private|         Rural|           154.24| 33.7|   never_smoked|     0|\n",
      "|  3|Female|36.0|           0|            0|         Yes|     Govt_job|         Urban|            72.63| 24.7|         smokes|     0|\n",
      "|  4|Female|62.0|           0|            0|         Yes|Self-employed|         Rural|            85.52| 31.2|formerly smoked|     0|\n",
      "|  5|Female|82.0|           0|            0|         Yes|      Private|         Rural|            59.32| 33.2|         smokes|     1|\n",
      "+---+------+----+------------+-------------+------------+-------------+--------------+-----------------+-----+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificando as primeiras 5 entradas\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a763b7",
   "metadata": {},
   "source": [
    "#### 1) Quantos registros (linhas) existem no arquivo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d208c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67135"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contagem de linhas\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfc17ec",
   "metadata": {},
   "source": [
    "#### 2) Quantas colunas existem no arquivo? Quantas são numéricas?\n",
    "###### R: 12 colunas e 7 são numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5912b553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- hypertension: integer (nullable = true)\n",
      " |-- heart_disease: integer (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- avg_glucose_level: double (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- smoking_status: string (nullable = true)\n",
      " |-- stroke: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificando os tipos de dados do Dataframe. \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8035ba6e",
   "metadata": {},
   "source": [
    "#### 3) No conjunto de dados, quantos pacientes sofreram e não sofreram derrame (stroke), respectivamente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a2f8854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|stroke|count|\n",
      "+------+-----+\n",
      "|     1|40287|\n",
      "|     0|26848|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agrupando a contgem dos valores da coluna stroke 0 (não) e 1(sim)\n",
    "\n",
    "df.groupBy(\"stroke\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c8f285",
   "metadata": {},
   "source": [
    "#### 4) Quantos pacientes sofreram derrame e trabalhavam respectivamente, no setor privado, de forma independente, no governo e quantas são crianças?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bce3ddd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|    work_type|count|\n",
      "+-------------+-----+\n",
      "| Never_worked|  177|\n",
      "|Self-employed|14736|\n",
      "|      Private|37806|\n",
      "|     children| 6156|\n",
      "|     Govt_job| 8260|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificando a quantidade de entradas dos tipos de trabalho (work_type)\n",
    "df.groupBy(\"work_type\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e20d6a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "|    work_type|stroke|\n",
      "+-------------+------+\n",
      "|Self-employed| 10807|\n",
      "|      Private| 23711|\n",
      "|     children|   520|\n",
      "|     Govt_job|  5164|\n",
      "+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criando uma tabela temporária\n",
    "df.createOrReplaceTempView('table')\n",
    "\n",
    "# Escrever consulta SQL\n",
    "consulta_work_type = \"\"\"\n",
    "SELECT work_type, COUNT(*) AS stroke\n",
    "FROM table\n",
    "WHERE stroke = '1'\n",
    "AND work_type NOT IN ('Never_worked')\n",
    "GROUP BY work_type\n",
    "\"\"\"\n",
    "\n",
    "# Executar consulta SQL\n",
    "resultado_work_type = spark.sql(consulta_work_type)\n",
    "\n",
    "# Mostrar o resultado na tela\n",
    "resultado_work_type.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "736a3a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|gender|count|\n",
      "+------+-----+\n",
      "|Female|39530|\n",
      "| Other|   11|\n",
      "|  Male|27594|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualização da quantidade de entradas dos generos participantes:\n",
    "df.groupBy(\"gender\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c43f22",
   "metadata": {},
   "source": [
    "#### 5) Escreva uma consulta com spark.sql para determinar a proporção, por gênero, de participantes do estudo. A maioria dos participantes é:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57b5e4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+----------+\n",
      "|gender|total_subjects|proportion|\n",
      "+------+--------------+----------+\n",
      "|Female|         39530|   58.8814|\n",
      "| Other|            11|    0.0164|\n",
      "|  Male|         27594|   41.1023|\n",
      "+------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Consulta SQL para determinar a proporção por gênero\n",
    "consulta_gender = \"\"\"\n",
    "SELECT gender,\n",
    "       COUNT(*) AS total_subjects,\n",
    "       ROUND (COUNT(*) / (SELECT COUNT(*) FROM table) * 100, 4) AS proportion\n",
    "FROM table\n",
    "GROUP BY gender\n",
    "\"\"\"\n",
    "\n",
    "# Executar consulta SQL\n",
    "resultado_gender = spark.sql(consulta_gender)\n",
    "\n",
    "# Mostrar o resultado na tela\n",
    "resultado_gender.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d52b2f",
   "metadata": {},
   "source": [
    "#### 6) Escreva uma consulta com spark.sql para determinar quem tem mais probabilidade de sofrer derrame: hipertensos ou não-hipertensos. Você pode escrever uma consulta para cada grupo. A partir das probabilidades que você obteve, você conclui que: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "66552c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|hypertension|count|\n",
      "+------------+-----+\n",
      "|           1|11017|\n",
      "|           0|56118|\n",
      "+------------+-----+\n",
      "\n",
      "+------+-----+\n",
      "|stroke|count|\n",
      "+------+-----+\n",
      "|     1|40287|\n",
      "|     0|26848|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualizando totais de entradas das variáveis hypertension e stroke\n",
    "df.groupBy('hypertension').count().show()\n",
    "df.groupBy('stroke').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1fafad2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|hypertension|count|\n",
      "+------------+-----+\n",
      "|           1| 8817|\n",
      "|           0|31470|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualizando totais de entradas da variável hypertension apenas quando stroke é igual 1 (pacientes que tiveram derrame)\n",
    "\n",
    "# Filtrando o dataframe\n",
    "df_filtered = df.filter(df.stroke == 1)\n",
    "\n",
    "# Visuzalizando o resultado\n",
    "df_filtered.groupBy('hypertension').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d36991c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+--------------------------+\n",
      "|prob_stroke_hypertension_1|prob_stroke_hypertension_0|\n",
      "+--------------------------+--------------------------+\n",
      "|        0.8003086139602432|        0.5607826365871913|\n",
      "+--------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criando uma tabela temporária\n",
    "df.createOrReplaceTempView('table')\n",
    "\n",
    "# Consulta SQL para calcular a probabilidade de sofrer um derrame com base na condição de hipertensão\n",
    "consulta_hypertension_stroke = \"\"\"\n",
    "    SELECT\n",
    "        AVG(CASE WHEN hypertension = 1 THEN stroke ELSE NULL END) AS prob_stroke_hypertension_1,\n",
    "        AVG(CASE WHEN hypertension = 0 THEN stroke ELSE NULL END) AS prob_stroke_hypertension_0\n",
    "    FROM\n",
    "        table\n",
    "\"\"\"\n",
    "\n",
    "# Executar consulta SQL\n",
    "resultado_hypertension_stroke = spark.sql(consulta_hypertension_stroke)\n",
    "\n",
    "\n",
    "# Mostrar o resultado na tela\n",
    "resultado_hypertension_stroke.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8e8593",
   "metadata": {},
   "source": [
    "##### R: os pacientes  hipertensos (hypertension = 1 equivalente a SIM, possui histórico de hipertensão) apresentaram maior proabilidade de sofrerem derrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c7aafd",
   "metadata": {},
   "source": [
    "#### 7) Escreva uma consulta com spark.sql que determine o número de pessoas que sofreram derrame por idade. Com qual idade o maior número de pessoas do conjunto de dados sofreu derrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efdab983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "| age|stroke|\n",
      "+----+------+\n",
      "|79.0|  2916|\n",
      "|78.0|  2279|\n",
      "|80.0|  1858|\n",
      "|81.0|  1738|\n",
      "|82.0|  1427|\n",
      "|77.0|   994|\n",
      "|74.0|   987|\n",
      "|63.0|   942|\n",
      "|76.0|   892|\n",
      "|70.0|   881|\n",
      "|66.0|   848|\n",
      "|75.0|   809|\n",
      "|67.0|   801|\n",
      "|57.0|   775|\n",
      "|73.0|   759|\n",
      "|65.0|   716|\n",
      "|72.0|   709|\n",
      "|68.0|   688|\n",
      "|69.0|   677|\n",
      "|71.0|   667|\n",
      "+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Consulta SQL para determinar a proporção por gênero\n",
    "consulta_age = \"\"\"\n",
    "SELECT age, COUNT(*) AS stroke\n",
    "FROM table\n",
    "WHERE stroke = '1'\n",
    "GROUP BY age\n",
    "\"\"\"\n",
    "\n",
    "# Executar consulta SQL\n",
    "resultado_age = spark.sql(consulta_age)\n",
    "\n",
    "# Ordenar o DataFrame em ordem descendente pela coluna 'stroke'\n",
    "resultado_age_ordenado = resultado_age.orderBy(\"stroke\", ascending=False)\n",
    "\n",
    "# Mostrar o resultado na tela\n",
    "resultado_age_ordenado.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc561872",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "#### 8) Usando a API de dataframes, determine quantas pessoas sofreram derrames após os 50 anos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58a56989",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de pessoas com derrame acima dos 50 anos:  28938\n"
     ]
    }
   ],
   "source": [
    "# Importando funções do pyspark.sql\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Filtrando as pessoas com mais de 50 anos\n",
    "resultado_age_filtrado = resultado_age_ordenado.filter(resultado_age_ordenado.age > 50)\n",
    "\n",
    "# Somando o total dessas pessoas\n",
    "resultado_age_50_mais = resultado_age_filtrado.agg(F.sum(\"stroke\")).collect()[0][0]\n",
    "\n",
    "# Printando resultado\n",
    "print(\"Total de pessoas com derrame acima dos 50 anos: \", resultado_age_50_mais) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36466ed3",
   "metadata": {},
   "source": [
    "#### 9) Usando spark.sql, determine qual o nível médio de glicose para pessoas que, respectivamente, sofreram e não sofreram derrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "382f1b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+\n",
      "|stroke|avg_gucose_level|\n",
      "+------+----------------+\n",
      "|     1|        119.9531|\n",
      "|     0|        103.6027|\n",
      "+------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Registro temporário do DataFrame para poder executar consultas SQL\n",
    "df.createOrReplaceTempView(\"table\")\n",
    "\n",
    "# Consulta SQL para calcular o nível médio de glicose para pessoas que sofreram ou não derrame\n",
    "stroke_avg_glucose_level = spark.sql(\"\"\"\n",
    "    SELECT stroke,\n",
    "           CONCAT(' ', ROUND(AVG(avg_glucose_level), 4)) AS avg_gucose_level\n",
    "    FROM data\n",
    "    GROUP BY stroke\n",
    "\"\"\")\n",
    "\n",
    "stroke_avg_glucose_level.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013734f",
   "metadata": {},
   "source": [
    "#### 10) Qual é o BMI (IMC = índice de massa corpórea) médio de quem sofreu e não sofreu derrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d9aeca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|stroke| avg_bmi|\n",
      "+------+--------+\n",
      "|     1| 29.9425|\n",
      "|     0| 27.9897|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Registro temporário do DataFrame para poder executar consultas SQL\n",
    "df.createOrReplaceTempView(\"table\")\n",
    "\n",
    "# Consulta SQL para calcular o nível médio de glicose para pessoas que sofreram ou não derrame\n",
    "stroke_bmi = spark.sql(\"\"\"\n",
    "    SELECT stroke,\n",
    "           CONCAT(' ', ROUND(AVG(bmi), 2)) AS avg_bmi\n",
    "    FROM data\n",
    "    GROUP BY stroke\n",
    "\"\"\")\n",
    "\n",
    "stroke_bmi.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41942071",
   "metadata": {},
   "source": [
    "#### 11) Crie um modelo de árvore de decisão que prevê a chance de derrame (stroke) a partir das variáveis contínuas/categóricas: idade, BMI, hipertensão, doença do coração, nível médio de glicose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd923056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.6864829789358091\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Determinando as coluans númericas para prever os derrames    \n",
    "numeric_cols = ['age', 'bmi', 'hypertension', 'heart_disease', 'avg_glucose_level']\n",
    " \n",
    "# Transformando o dataframe em um vetor com colunas categóricas   \n",
    "vec_assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"features\")\n",
    "\n",
    "# Criando o objeto que será usado para treinar o modelo de Árvore de Decisão\n",
    "dtc = DecisionTreeClassifier(labelCol='stroke', featuresCol='features')\n",
    "\n",
    "# Criando o pipeline do modelo\n",
    "pipeline = Pipeline(stages=[vec_assembler, dtc])\n",
    "\n",
    "# Separando os dados em treinamento e teste\n",
    "train_data, test_data = df.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Treinamento dos dados\n",
    "pipeline_model = pipeline.fit(train_data)\n",
    "\n",
    "# Execução da previsão\n",
    "predictions_df = pipeline_model.transform(test_data)\n",
    "\n",
    "# Avaliando a acurácia das previsões\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy', labelCol='stroke')\n",
    "print(f\"Acurácia: {evaluator.evaluate(predictions_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52431d",
   "metadata": {},
   "source": [
    "#### 12) Adicione ao modelo as variáveis categóricas: gênero e status de fumante. Use o conteúdo da aula interativa para lidar com as variáveis categóricas.  A acurácia (qualidade) do modelo aumentou para:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bebde6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|gender|\n",
      "+------+\n",
      "|Female|\n",
      "| Other|\n",
      "|  Male|\n",
      "+------+\n",
      "\n",
      "+---------------+\n",
      "| smoking_status|\n",
      "+---------------+\n",
      "|         smokes|\n",
      "|   never_smoked|\n",
      "|formerly smoked|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analisando os valores distintos das colunas que serão acrescentadas ao modelo\n",
    "df.select('gender').distinct().show()\n",
    "df.select('smoking_status').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdcdd5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "# Determinando as coluans categóricas e numéricas para prever os derrames    \n",
    "categorical_cols = ['gender', 'smoking_status']\n",
    "numeric_cols = ['age', 'bmi', 'hypertension', 'heart_disease', 'avg_glucose_level']\n",
    "\n",
    "# Convertendo valores categóricos string para numéricos\n",
    "stringIndexer = StringIndexer(inputCols=categorical_cols, outputCols=[x + \"Index\" for x in categorical_cols]) \n",
    "oneHotEncoder = OneHotEncoder(inputCols=stringIndexer.getOutputCols(), outputCols=[x + \"OHE\" for x in categorical_cols])\n",
    "\n",
    "# Agrupando todas as colunas\n",
    "all_cols = [c + \"OHE\" for c in categorical_cols] + numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ca30d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.8386762675083843\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Transformando o dataframe em um vetor com colunas categóricas   \n",
    "vec_assembler = VectorAssembler(inputCols=all_cols, outputCol=\"features\")\n",
    "\n",
    "# Criando o objeto que será usado para treinar o modelo de Árvore de Decisão\n",
    "dtc = DecisionTreeClassifier(labelCol='stroke', featuresCol='features')\n",
    "\n",
    "# Criando o pipeline do modelo\n",
    "pipeline = Pipeline(stages=[stringIndexer, oneHotEncoder, vec_assembler, dtc])\n",
    "\n",
    "# Separando os dados em treinamento e teste\n",
    "train_data, test_data = df.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Treinamento dos dados\n",
    "pipeline_model = pipeline.fit(train_data)\n",
    "\n",
    "# Execução da previsão\n",
    "predictions_df = pipeline_model.transform(test_data)\n",
    "\n",
    "# Avaliando a acurácia das previsões\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy', labelCol='stroke')\n",
    "print(f\"Acurácia: {evaluator.evaluate(predictions_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0ecb32",
   "metadata": {},
   "source": [
    "### Podemos concluir que, as variáveis status de fumante (smoking_status) e genero (gender), apresentaram maior acurácia no modelo, melhorando o fit para previsão dos derrames."
   ]
  }
 ],
 "metadata": {
  "direction": "ltr",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
